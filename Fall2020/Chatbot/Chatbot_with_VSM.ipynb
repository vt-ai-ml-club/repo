{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Chatbot_with_VSM.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vt-ai-ml-club/repo/blob/master/Fall2020/Chatbot/Chatbot_with_VSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-UVUK-eHQiy"
      },
      "source": [
        "## Building a chatbot using a VSM\n",
        "\n",
        "Reference: https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8649OI-tHRt5"
      },
      "source": [
        "# download data\n",
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/vt-ai-ml-club/repo/master/Fall2020/Chatbot/chatbot_corpus.txt'\n",
        "corpus = requests.get(url).text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Va76yIHQi0"
      },
      "source": [
        "data = corpus.rstrip().split('\\n')\n",
        "data[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHDkN_fHQi4"
      },
      "source": [
        "question_to_responses = {}\n",
        "questions = set()\n",
        "\n",
        "# Creating a key, value pair as <question,response>\n",
        "for i in range(0, len(data), 2):\n",
        "    question = data[i]\n",
        "    response = data[i+1]\n",
        "    \n",
        "    responses = question_to_responses.setdefault(question, [])\n",
        "    responses.append(response)\n",
        "    questions.add(question)\n",
        "    \n",
        "question_list = list(questions)\n",
        "print(question_list[-5:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hqy8p-UHQi6"
      },
      "source": [
        "import string\n",
        "import nltk     # natural language toolkit (popular Python module for NLP)\n",
        "\n",
        "nltk.download('punkt')    # to remove punctuation\n",
        "nltk.download('wordnet')  # a lemmatization dictionary\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "remove_punctuation_table = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def normal_lemma_tokenizer(text):\n",
        "    normalize_text = text.lower().translate(remove_punctuation_table)           # normalize text (remove puncutation)\n",
        "    tokens = nltk.word_tokenize(normalize_text)                                 # tokenize text (separate into words)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]       # lemmatize each token (find base word)\n",
        "    return lemmatized_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk81VqBCHQi8"
      },
      "source": [
        "import random\n",
        "\n",
        "def select_random_response(question):\n",
        "    return random.choice(question_to_responses[question])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T23Ynw5NHQi-"
      },
      "source": [
        "### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        ">**Term Frequency**: scores the frequency of a word in the current document.\n",
        "\n",
        "$$ TF(w,d) = \\frac{\\text{# of times w appears in d}}{\\text{total # of words in the d}} $$\n",
        "\n",
        ">**Inverse Document Frequency**: scores how rare the word is across all documents.\n",
        ">+ A word with a *low* IDF score is a *common* word.\n",
        ">+ A word with a *high* IDF score is a *uncommon* word.\n",
        "\n",
        "$$ IDF(w,D) = \\log{(\\frac{\\text{total # of documents}}{\\text{# of documents containing w}})} $$\n",
        "\n",
        "\n",
        "\n",
        "### Word Similarity \n",
        ">**Cosine similarity**: is the measure of similarity between two vectors. In our case, the similarity between two questions.\n",
        "\n",
        "$$ cos(u,v) = \\frac{u \\cdot v}{\\left\\lVert u \\right\\lVert \\left\\lVert v \\right\\lVert} $$\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/vt-ai-ml/fall2019-meetings/raw/master/data/chatbot_cosine_image.png\" align=\"left\" style=\"width:250px;height:250px;\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP3JBnK0HQi_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def respond(user_question):\n",
        "    question_list.append(user_question)\n",
        "    \n",
        "    # Maps user response and questions into TF-IDF vector space, where each word is a dimension\n",
        "    tf_idf_matrix = tf_idf_vector_space.fit_transform(question_list)\n",
        "    \n",
        "    # Calculate the cosine similarity of user's response with other vectors (question) in the vector space\n",
        "    user_question_tf_idf = tf_idf_matrix[-1]\n",
        "    similarity_score = cosine_similarity(user_question_tf_idf, tf_idf_matrix[:-1])\n",
        "    \n",
        "    # Find the most similar vector (question) to our user's response\n",
        "    highest_tf_idf_idx = similarity_score.argmax()\n",
        "    highest_tf_idf = similarity_score.max()\n",
        "    \n",
        "    # Find appropriate response\n",
        "    if(highest_tf_idf == 0): # no similarity\n",
        "        robo_response = \"I don't understand what you're saying.\"\n",
        "    else:\n",
        "        robo_response = select_random_response(question_list[highest_tf_idf_idx])\n",
        "        \n",
        "    question_list.remove(user_question)\n",
        "    return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxDfrBIxHQjB"
      },
      "source": [
        "tf_idf_vector_space = TfidfVectorizer(tokenizer=normal_lemma_tokenizer)\n",
        "\n",
        "print(\"Chatbot is on! Type 'exit' to turn off the chatbot.\\n\\\")\n",
        "while(True):\n",
        "    user_question = input().lower().translate(remove_punctuation_table)\n",
        "    \n",
        "    if(user_question == 'exit'):\n",
        "        print('Chatbot is now off!')\n",
        "        break\n",
        "    else:\n",
        "        print(\"BOT: \", respond(user_question), '\\n')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3cgoFFaHQjD"
      },
      "source": [
        "### Questions to ask your chatbot\n",
        "* How is everything going?\n",
        "* Tell me a joke\n",
        "* What is a chat robot?\n",
        "* What can you eat?"
      ]
    }
  ]
}